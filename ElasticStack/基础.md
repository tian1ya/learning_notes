#### .什么是ES

> `es` 是企业级的，近实时的的全文搜索硬气，性能优秀，是目前最受欢迎的全文搜索硬气
>
> 实时性比`Solr` 好
>
> 是基于`Lucence` 开发的，分布式的搜索引擎
>
> `ES` 使用场景
>
> * 企业级检索
> * 分析，支持不太复杂的业务分析，支持`SQL` 和 聚合计算
> * 日志运维，企业中的一些运维人员可以根据`ES` 中的日志来快速排错
> * 作为传统数据库的补充，因为它本身非常擅长检索，可以结合`Mysql` 使用
>
> `ElasticStack(ELK)`  现在组件越来越多
>
> * `LogStask` 数据采集，实时数据采集
> * `Kibana` 可视化工具

#### ES 核心概念

##### 索引

> 一个索引就是一个拥有几份相似特征的文档的集合，比如说一个客户数据的索引，另一个产品目录的索引，还有一个订单数据的索引。ES 中是先建立索引，然后插入文档
>
> 一个索引由一个名字来标识(必须全部是小写字母的)，并且当我们要对应与这个索引中的文档进行索引，搜索，更新和删除的时候，都需要使用到这个名字
>
> 在一个集群中，可以定义任意多的索引

##### 映射 mapping

> `ES` 中的映射用来定义一个文档，一个索引可以对应一个映射
>
> mapping 是处理数据的方式和规则方面做一些限制，如某个字段的数据类型，默认值，分析器，是否被索引等，这些都是映射里面可以设置的。

##### 字段 Field

> 相当于是数据表的字段，对文档数据根据不同属性进行的分类标识

##### 类型Type

> 每一个字段都应该有一个对应的类型，如Text/Byte 等

##### 文档 document

> 一个文档是一个可被索引的基础信息单元，是主要的存在实体，比如，可以拥有某一个客户的文档，某一个产品的一个文档，当然也可以拥有某个订单的一个文档，文档以`JSON`  的格式表示。

---

#### 分区和副本 shards & replicas

##### 分片

* 一个索引可以存储超过单个节点硬件限制的大量数据，比如一个有10亿文档的所有站1TB 的磁盘空间，而任一个节点都没有这样大的磁盘空间，或者单个节点的处理索索请求响应太慢。
* 为了解决这个问题，`ES` 提供了将索引划分为多份的能力，这些份就是分片。
* 当创建一个索引的时候，可以指定你想要的分片的数量
* 每个分片本身也是一个功能完善并且独立的索引，这个索引可以被放置到集群中的任何节点、
* 分片很重要，主要是一下2个原因
  * 允许水平分割、扩张你的内容质量
  * 允许在分片之上进行分布式的，并行的操作，进而提供性能/吞吐
* 一个分片如何分布，它的文档怎么聚合会搜索请求，是完全由 `ES`  管理的，对于用户而言，这些都是透明的。

##### 副本

在一个网络环境中，失败是随时都会发生的，在某个分片/节点不知怎么的就处理离线状态或者由于任何原因小时了，这种情况下，有一个故障转移机制是非常有用的，为此目的，`ES` 允许你创建分片的一份或者多份拷贝，这些拷贝叫做**副本分片**。

**副本的重要体现在**

* 提供了高可用性，注意到副本分片从不和原/主分片放在同一个节点上
* 扩展搜索量/吞吐量，因为搜索可以在所有的副本上并行运行
* 每个索引被分为多个分片，一个索引有0个或者多个副本
* 一旦设置了副本，每个索引就有了主分片和副本分片，分片和副本的数量可以在索引创建的时候指定
* 在索引创建后，可以在任何时候动态的改变副本的数量，但是不能改变分片的数据

> 可以将分片理解为spark/kafka 中的分区，然后分区是不能改变的，改变意味着shuffle ，当然这里是没有shuffle 概念的，就是会发生数据在集群中传来传去，通信IO等。
>
> 副本就是存储多余一份数据，做备份。

---

#### 分词器作用和使用

elasticsearch能够快速的通过搜索词检索出对应的文章归功于倒排索引

下面通过三个文档示例，看看它是如何分词的

文档1: 我爱伟大的祖国

文档2: 祝福祖国强大繁

文档3: 我爱蓝天白云

经过中文分词器,以上文档均会根据分词规则,将文档进行分词后的结果如下:

注意:不同的分词规则,分词结果不一样,选择根据分词器提供的分词规则找到适合的分词规则

文档1分词结果： [我,爱,伟大,的,祖国]

文档2分词结果： [祝福,祖国,强大,繁盛]

文档3分词结果： [我,爱,蓝天白云,蓝天,白云]

通过上面的分词结果，发现拆分的每个词都是我们熟知的词语， 但是如果不使用中文分词，就会发现上面的文档把每个字拆分成了一个词，对我们中文检索很不友好。

**再看倒排索引**

看到上面中文分词器结果,就会有新的疑问,使用中文分词器那样分词效果有什么好处呢? 答案就是根据分词建立词汇与文档关系的倒排索引。这步都是es帮我们做的,下面通过"我","爱","祖国"三个词看看倒排索引,如下图:

![a](./pics/分词.png)

通过上图中的倒排索引,我们搜索"祖国"时,es通过倒排索引可以快速的检索出文档1和文档2。如果没有中文分词器,搜索"祖国"就会被拆分"祖""国"两个词的倒排索引, 就会把包含"祖"的文档都检索出来,很明显就会和我们想要的结果大相径庭。

---

[docker 安装ES](https://zhuanlan.zhihu.com/p/257867352)

