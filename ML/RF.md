在决策树那章节，学习到将数据集进行不停的切分，使得最后落到树叶子节点的数据是最纯的。

![aggregation](./pic/rf.png)

DT 是不停的在某一个计算标准上切割数据集，进行树的生长，当数据集发生一些变化的时候，那么切分就会不一样，所以每次训练出来的树的方差就会比较大。

Bagging 的方法是通过boostrap 的方法获取一份一份的数据，然后将数据喂给某个模型，模型去学习，然后将不同数据集中学习到的模型使用投票或者均值的方法得到最终的结果。通过最后投票或者均值的方法使得最终bagging 的模型的方法能够减少。

**那么是否可以将二者结合起来，就解决了一些问题。** aggregation

也就是将上面bagging 中的第二步你和模型的时候使用DT。每次都是独立的去学习一棵树，数据和模型之间没有什么依赖的地方，所以训练模型可以并行化

![aggregation](./pic/rf2.png) 

在之前提到过增加模型的差异性可以将集成后的模型的性能增加，而bagging 是在数据集的量方面进行抽样，那么还有一种就是在特征方面也可以完成抽象，这也是RF给bagging 新加进来的特性

![aggregation](./pic/rf3.png)

此外RF还做了随机投影的事情，将输入的数据随机投影到一个低维度空间，然后在这个空间上做模型拟合

![aggregation](./pic/rf4.png)

所以rf做了3件事情，使得数据集更加的不一样，使得训练出来的模型差异性更大。

---

在做bagging 的时候，数据中会选中一部分，还会有一部分选不中，那么选不中的数据称为是Out-of-bag（OOB）数据。

![aggregation](./pic/bagging1.png)

boostrap 的过程中会有多少数据没有被选中呢》

![aggregation](./pic/bagging2.png)

而这些OOB的数据，就可以当做是每次训练基模型的验证数据集，去评价当前基模型，这是可行的，因为当前基模型并没有使用oob的数据去训练，但是很少这样使用，因为集成学习的前提就是基模型是弱模型，自然它的性能不是会很好。但是还有一个使用时是，在使用oob评价基模型之后在最后将所有基模型的评价汇总，作为最终输出模型的评价指标。

![aggregation](./pic/bagging3.png)

也就是使用oob评价，而不用使用专门的评价数据集去评价

![aggregation](./pic/fe.png)

如上图使用permutation的方式随机污染一个特征去测试这个特征的重要性，而在rf中验证的时候使用的是将oob的数据中某一个特征进行污染，根据污染前后的评价的涨幅去决定改特征的重要性，这样就避免了使用重新训练的方式去得到特征的重要性。

![aggregation](./pic/fe2.png)

这里例子中，当一个特征的值都是固定的，那么对这个特征进行污染与否并去测试重要性当不会有什么影响，因为在怎么随机将这个列选出来，那么它的值还是不变的，

![aggregation](./pic/rfSummary.png)

