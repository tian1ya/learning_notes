**Delta Lake**: Reliable Data Lakes at Scale

任何一个轮子都有被造出来的原因，Delta Lake项目出现的原因是什么、为了解决什么问题、怎么使用、使用场景，有什么缺点、是否有别的更好的组件替代。更深的就是深入源码弄懂整个流程是什么。

Delta Lake是一个数据湖产品，什么是数据湖？？ 数据仓库是将数据进行ETL，存入HDF或者别的数据库。 数据湖是将所有类型的数据不进行处理，直接存入，做分析时，才将数据进行ETL。但是数据不进行处理全存到数据湖中会出现问题。

1.数据湖中的数据质量低，会出现垃圾数据。2.随着数据量的增加，性能增加 3.更新数据湖中的记录很难。

所以Delta Lake是为了解决这些而被创造出来的。
————————————————
原文链接：https://blog.csdn.net/qq_24186017/article/details/90482483

> is an open-source storage layer that brings ACID transactions to Apache Spark™ and big data workloads.

![aaa](./pic/DeltaLake.png)

> Delta Lake 是一个存储层，为[ Apache Spark ](https://spark.apache.org/)和其他大数据引擎提供可伸缩的 ACID 事务，让用户可以基于 HDFS 和云存储构建可靠的数据湖。此外，Delta Lake 还提供了内置的数据版本控制，可以方便地回滚以及重新生成报告。

**一些背景知识**

> * 数据湖： 它是一种大型数据**存储库**和**处理引擎**，能够存储大量各种类型的数据，拥有强大的信息处理能力，数据库面临一些问题
>
>   * 数据库的读写的不可靠性：在数据写入的时候数据的不连续性，导致读取的时候看到不一致的数据。
>   * 数据质量低：写入非结构化数据伴随着数据质量的下降(非结构化数据没有schame或者其他严重数据质量的方法)。
>   * 数据量提升伴随着处理能力的下降，处理作业/查询在处理元数据上话费大量时间。
>   * 数据的更新困难：工程师在更新数据的时候会有这么中情况，构建处理 pipeline 读取全部partition 数据，处理，然后写入，这个过程是很抵效。
>
> * 乐观锁并发控制：
>
>   **乐观并发控制**（又名“**乐观锁**”，Optimistic Concurrency Control，缩写“OCC”）是一种[并发控制](https://zh.wikipedia.org/wiki/并发控制)的方法。它假设多用户并发的[事务](https://zh.wikipedia.org/wiki/数据库事务)在处理时不会彼此互相影响，各事务能够在不产生锁的情况下处理各自影响的那部分数据。在[提交](https://zh.wikipedia.org/w/index.php?title=提交_(SQL)&action=edit&redlink=1)数据更新之前，每个事务会先检查在该事务读取数据后，有没有其他事务又修改了该数据。如果其他事务有更新的话，正在提交的事务会进行[回滚](https://zh.wikipedia.org/wiki/回滚_(SQL))

**数据湖的一些问题**

> 1. **对数据湖进行的读写操作不可靠**。数据工程师经常遇到数据湖写入不安全的问题，这会导致读取方在写入期间看到垃圾数据。它们必须构建变通方案，确保读取方在写操作期间看到的数据始终一致。
> 2. **数据湖的数据质量较差**。将非结构化数据转储到[数据湖](https://databricks.com/glossary/data-lake)中很容易。但这是以数据质量为代价的。如果没有任何机制验证模式和数据，那么数据湖就会受到数据质量差的影响。因此，试图挖掘这些数据的分析项目也会失败。
> 3. **随着数据量的增加，性能变差**。随着转储到数据湖中的数据量的增加，文件和目录的数量也会增加。处理数据的大数据作业和查询引擎在处理元数据操作上花费了大量时间。这个问题在流作业的情况下会更加明显。
> 4. **更新数据湖中的记录非常困难**。工程师需要构建复杂的管道来读取整个分区或表，修改数据并将其写回。这样的管道效率低下，难以维护。

**DL解决了上述问题，简化了数据湖构建**

**DL提供如下能力**

> * ACID 事务，提供多个写操作之间的 ACID 事务。每个写操作都是一个事务，事务日志中记录的写操作有一个串行顺序。事务日志会跟踪文件级的写操作，并使用[乐观并发控制](https://en.wikipedia.org/wiki/Optimistic_concurrency_control)，这非常适合数据湖，因为尝试修改相同文件的多个写操作并不经常发生。在存在冲突的场景中，Delta Lake 会抛出一个并发修改异常，以便用户处理它们并重试它们的作业。Delta Lake 还提供了强大的[序列化隔离级别](https://en.wikipedia.org/wiki/Isolation_(database_systems)#Serializable)，允许工程师不断地对目录或表进行写操作，而用户可以不断地从相同的目录或表中读取数据。读取者将看到读操作开始时存在的最新快照。
>
> * Schema 管理，会自动验证正在写入的 DataFrame 模式是否与表的模式兼容。表中存在但 DataFrame 中不存在的列会被设置为 null。如果 DataFrame 中有额外的列在表中不存在，那么该操作将抛出异常。Delta Lake 具有可以显式添加新列的 DDL 和自动更新模式的能力。
>
>   表或目录的元数据信息存储在事务日志中，而不是存储在元存储（metastore）中。这使得 Delta Lake 能够在固定的时间内列出大型目录中的文件，并且在读取数据时非常高效。
>
> * 数据版本，基于视觉戳或者版本号保存历史数据版本。可以恢复数据。
>
> * 结合spark Stream 除了批处理写之外，Delta Lake 还可以使用[ Apache Spark 的结构化流](https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html)作为高效的流接收。再结合 ACID 事务和可伸缩的元数据处理，高效的流接收现在支持许多接近实时的分析用例，而且无需维护复杂的流和批处理管道。
>
> * 数据存储格式采用开源方法 Parque
>
> * 记录数据的更新和删除()
>
> * 完全兼容 sparkAPI。
>

