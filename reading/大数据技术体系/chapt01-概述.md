* 企业级大数据技术框架 - 以电子商务应用为例

  > 1. 用户在浏览器通过淘宝查看/购买商品
  > 2. 向淘宝后端发送HTTP 请求
  > 3. 将请求记录到大数据系统，并返回相应的内容
  > 4. 大数据系统中记录着用户的行为数据，通过理解这些行为数据，进而进行广告投放、商品推荐等

* 大数据处理包括6个主要环节

  > 1. 数据收集
  > 2. 数据存储
  > 3. 资源管理
  > 4. 服务协调
  > 5. 计算引擎
  > 6. 数据分析
  > 7. 数据可视化
  >
  > ![aa](./imgs/bigdataF.PNG)

* 数据收集层

  > 直接和数据源对接的模块，负责将数据源中的数据接近实时收集到一起，数据具有 分布式、异构性、多样化及流式等特点
  >
  > 1. 分布式：数据分布到多台机器上个，并通过网络连接在一起
  > 2. 异构性：任何能够产生数据的系统均可以成为数据源
  > 3. 多样化：数据格式多样化
  > 4. 流式产生：数据源同”水龙头“一样，源源不断的产生”流水“（数据）

* 数据存储层

  > 将海量结构化/非结构化数据的存储
  >
  > 1. 扩展性
  > 2. 容错性
  > 3. 存储模型 

* 资源和服务协调层

  > 全部应用统一使用一个集群资源，统一调度/使用

* 计算引擎层

  > 1. 批处理： 追求高吞吐量,即单位时间内处理的数据量尽可能大，典型的应用有搜索引擎构建索引、批量数据分析等。
  > 2. 实时计算：追求低延迟,一般处理延迟在秒级以内，典型的应用有广告系统、舆情监测等。
  >
  > 二者是矛盾的两个优化方向。现在计算引擎的发展，趋向于 ”小而美“，也就是单独构建一个计算引擎，每种计算引擎只专注于一件事情，
  >
  > ![aa](./imgs/cumpEn.PNG)

* 数据分析层

  > 之间和用户程序对接，为其提供易用的数据处理工具，典型的使用有：使用批处理收产生小规模的数据，然后在此基础上使用交互式处理工具进行快速处理。

* 数据可视化层



---

* Google 大数据技术栈

  > Google 基本是大数据发展的引领者
  >
  > ![aa](./imgs/gBigData.PNG)

  > 1. GFS: 分布式文件系统，具有良好的容错性、扩展性和可用性，**尤其是容错性表现突出**，这使得GFS可构建在大量普通廉价机器上，进而容易进行“Scale out”（横向扩展），相比于传统的“Scale up”（向上扩展）方案中采用的大型机或小型机等，大大降低了成本。
  > 2. BigTable: 构建在GFS之上的分布式数据库本质上是一个稀疏的、分布式的、持久化存储的多维度排序映射表。BigTable支持插入和更新等操作，且行数和列数可以无限扩展，这在很大程度上弥补了传统关系型数据库在schema上的不灵活。
  > 3. MegaStore: 构建在BigTable之上，支持ACID特性的分布式数据库。它是一个具有高扩展性并可进行高密度交互的可用存储服务，其在Google的基础系统之中，起初主要解决App Engine的数据存储问题。MegaStore能够在广域网中同步复制文件写操作，在可接受的延时下，支持跨数据中心的故障迁移。
  > 4. Spanner: 可扩展的、多版本、全球分布式、支持同步复制的数据库。它是第一个把数据分布在全球范围内的系统，并且支持外部一致性的分布式事务。

* Hadoop 和 Spark 开源大数据技术栈

  > 目前开源社区已经积累了比较完整的大数据技术栈，应用最广泛的是以Hadoop与Spark为核心的生态系统。整个大数据技术栈涉及数据收集、数据存储、资源管理与服务协调、计算引擎和数据分析这五个层级。
  >
  > ![aa](./imgs/hadoopSpark.PNG)
  >
  > * 数据收集层
  >
  >   > 主要由关系型与非关系型数据收集组件，分布式消息队列构成。
  >   >
  >   > 1. Sqoop/Canal: 关系型数据收集和导入工具，是连接关系型数据库（比如MySQL）和Hadoop（比如HDFS）的桥梁，Sqoop可将关系型数据库中的数据全量导入Hadoop，反之亦可，而Canal则可用于实现数据的增量导入。
  >   > 2. Flume: 非关系型数据收集工具，主要是流式日志数据，可近实时收集，经过滤，聚集后加载到HDFS等存储系统。
  >   > 3. Kafka: 分布式消息队列，一般作为数据总线使用，它允许多个数据消费者订阅并获取感兴趣的数据。相比于其他消息队列，它采用分布式高容错设计，**更适合大数据应用场景。**
  >
  > * 数据存储层
  >
  >   >  主要由分布式文件系统（面向文件的存储）和分布式数据库（面向行/列的存储）构成。
  >   >
  >   > 1. HDFS Google GFS的开源实现，具有良好的扩展性与容错性等优点，尤其是出色的容错机制设计，使得它非常适合构建在廉价机器上，这大大降低了大数据存储成本
  >   > 2. HBase: 构建在HDFS之上的分布式数据库，Google BigTable的开源实现，允许用户存储结构化与半结构化的数据，支持行列无限扩展以及数据随机查找与删除。
  >
  > * 资源管理和服务协调
  >
  >   >  YARN: 统一资源管理和调度系统，管理集群中的各种资源（CPU/内存等），并按照一定的策略分配给上层各类应用
  >   >
  >   > 2. ZooKeeper： 允许用户通过简单的API实现leader选举、服务命名、分布式队列与分布式锁等复杂的分布式通用模块。
  >
  > * 计算引擎
  >
  >   > 批处理/交互式处理/流式实时处理
  >   >
  >   > 1. MapReduce/Tez： MapReduce是一个经典的批处理计算引擎，它是GoogleMapReduce的开源实现，具有良好的扩展性与容错性，允许用户通过简单的API编写分布式程序；Tez是基于MapReduce开发的通用DAG（Directed Acyclic Graph的简称，有向无环图）计算引擎，能够更加高效地实现复杂的数据处理逻辑，目前被应用在Hive、Pig等数据分析系统中。
  >   > 2. Spark：通用的DAG计算引擎，它提供了基于RDD（Resilient Distributed Dataset）的数据抽象表示，允许用户充分利用内存进行快速的数据挖掘和分析
  >   > 3. Impala/Presto： 分别由Cloudera和Facebook开源的MPP（MassivelyParallelProcessing）系统，允许用户使用标准SQL处理存储在Hadoop中的数据。它们采用了并行数据库架构，内置了查询优化器，查询下推，代码生成等优化机制，使得大数据处理效率大大提高。
  >   > 4. Storm/Spark Streaming：分布式流式实时计算引擎，具有良好的容错性与扩展性，能够高效地处理流式数据，它允许用户通过简单的API完成实时应用程序的开发工作。
  >
  > * 数据分析层：为方便解决大数据问题而提供的各种数据分析工具
  >
  >   >Hive/Pig/SparkSQL:
  >   >
  >   >Mahout/MLlib
  >   >
  >   >Apache Beam/Cascading: 基于各类计算框架而封装的高级API，方便用户构建复杂的数据流水线。Apache Beam统一了批处理和流式处理两类计算框架，提供了更高级的API方便用户编写与具体计算引擎无关的逻辑代码；Cascading内置了查询计划优化器，能够自动优化用户实现的数据流。采用了面向tuple的数据模型，如果你的数据可表示成类似于数据库行的格式，则使用Cascading处理将变得很容易。

* 大数据框架： Lambda Architecture

  > 是一种大数据软件架构设计，其目的是指导用户充分利用批处理和流式计算技术各自的优点实现一个复杂的大数据处理系统，**通过两种技术的结合在延迟、吞吐量和捅错之间找到平衡点**
  >
  > ![aa](./imgs/lambdaA.PNG)
  >
  > 批处理层： 它的主要思想是利用分布式批处理计算，以批为单位处理数据，并产生一个经预计算产生的只读数据视图。该层将数据流看成只读的、仅支持追加操作的超大数据集。它可以一次性处理大量数据，引入复杂的计算逻辑（比如机器学习中的模型迭代计算，历史库的匹配等），其优点是吞吐率高，缺点是数据处理延迟高，即从数据产生到最终被处理完成，整个过程用时较长，通常是分钟或小时级别。
  >
  > 流式处理层：为了降低批处理层带来的高延迟，LA又引入了流式处理层，该层采用流式计算技术，大大降低了数据处理延迟（通常是毫秒或秒级别），其优点是数据处理延迟低，缺点是无法进行复杂的逻辑计算，得到的结果往往是近似解。
  >
  > 服务层：批处理层和流式处理层可以结合在一起，这样既保证数据延迟低，也能完成复杂的逻辑计算（只能保证最终一致性）。为了整合两层的计算结果，LA进一步引入服务层，它对外提供了统一的访问接口以方便用户使用。

