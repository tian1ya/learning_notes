#### Kafka 的用途有哪些，以及使用场景

* 消息系统

> 和传统的消息系统都具备系统解耦，冗余存储，流量削峰，缓冲、异步通信等功能，其次还提供了大多数消息系统都难以实现的顺序性保证以及回溯消费的功能

* 存储系统

> kafka 可以将消息数据以分布式的方式存放到磁盘。通过配置存储方式可以实现永久存储

* 流式处理平台

> Kafka 不仅仅为流式处理框架提供可靠的数据来源，还提供了一个完整的流式处理平台，比如窗口、连接以及聚合操作等。



#### Kafka 中的 ISR、AR、OSR 等分别代表什么

#### Kafka 中的 HW LEO LW 分别代表什么

> 注意 HW = min(LEO from ISR)

#### Kafka 中是如何体现消息的顺序的

> 和分区的的关联。
>
> 分区的有序性，topic 下的无序

#### Kafka 中的分区器、序列化器、拦截器，以及处理顺序

> 注意先解释解释三者的功能。
>
> 序列化: 对象变为字节数组

#### 客户端的整体框架是咋样的，有几个线程

> 主线程和 sender 线程

#### 新旧 Kafka 客户端的区别

> 注意区别， offset 放在 Zookeeper 中/放在 Beoker 中
>
> Zookeeper 不适合频繁的读写

#### 消费组中的消费者个数如果超过 topic 的数量，那么就会有消费者消费不到数据？这是否正确，如果正确那么有什么 hack 的手段？

> 一般而言当消费者组中消费者个数大于分区个数，就会有消费者消费不到数据
>
> 可以公国自定义 AbstractPartitionAssignor 实现消费策略，从而实现同一组消费内的任意消费者都可以消费订阅主题。

#### 说一些造成重复消费的例子

* `rebalance` 消费者自动提交偏移量导致

> 消费者A，第一次poll 了100条数据，刚好这个时候到了提交偏移量的时候，提交了偏移量，偏移量到了 100+1,在后面的操作中，消费了 100 条数据，但是这个时候还没有到提交偏移量的时候，这个时候由于添加进来消费者，发生了重平衡，更好有另外一个消费者B消费该分区的数据，但是消费者A 还没有提交第二次的消费便宜，而这个时候消费者B就重复消费了消费者A 消费的东西。

* 消费者手动提交消费

> 和上面的例子一样，当poll 了消费，然后在消费，在消费的过程中发生了异常，或者宕机，或者发生了在平衡，而这个时候偏移量还没有提交，那么下次再 poll 消费的时候就会发生重复消费。

#### 哪些情况会造成漏消费

也就是没有消费

* 在设置 `ACK = 1(default)` 的时候

> 生产者发送了消息，leader 收到了信息，然后就返回了收到消息的通知，但是这个时候刚刚好leade 挂了， follower 也没有从leader 中同步来信息，这个时候这个消息就会丢失。

* 在设置 `ACK = 0` 的时候

> 也就是生产者发后就忘，不管broker 收到没有，只要生产者发送完消息，就当broker 以及收到消息了，这个时候实现最大吞吐，但是最容易导致消息丢失

* 在设置 `ACK = -1/all` 的时候 + `partition 副本=1`

> 这个 ack 值下，需要等所有的 `ISR` 都均收到才收到消息，才算发送成功，但是这里partition 的分区只有1，那么就退回到 `ack=1` 的情况。

#### 如何实现可靠性

* 生产者可靠性保证

> `ack=all`, retries = N,

* broker

> Replication.factor 副本至少 > 1
>
> min.insync.replicas > 1 ISR 副本数量至少2个

* 消费者

> 手动消费偏移
>
> 消费完在提交





